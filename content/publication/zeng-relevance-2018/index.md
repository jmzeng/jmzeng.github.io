---
title: The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep Bayesian
  Active Learning
authors:
- Jiaming Zeng
- Adam Lesnikowski
- Jose M. Alvarez
date: '2018-11-01'
publishDate: '2023-12-16T17:13:24.207440Z'
publication_types:
- manuscript
publication: Third workshop on Bayesian Deep Learning (NeurIPS 2018)
abstract: One of the main challenges of deep learning tools is their inability to
  capture model uncertainty. While Bayesian deep learning can be used to tackle the
  problem, Bayesian neural networks often require more time and computational power
  to train than deterministic networks. Our work explores whether fully Bayesian networks
  are needed to successfully capture model uncertainty. We vary the number and position
  of Bayesian layers in a network and compare their performance on active learning
  with the MNIST dataset. We found that we can fully capture the model uncertainty
  by using only a few Bayesian layers near the output of the network, combining the
  advantages of deterministic and Bayesian networks.
summary: Our work explores whether fully Bayesian networks are needed to successfully capture model uncertainty.
tags:
- Computer Science - Artificial Intelligence
- Computer Science - Machine Learning
- Statistics - Machine Learning
featured: true
links:
- name: URL
  url: http://arxiv.org/abs/1811.12535
- name: Github
  url: https://github.com/tensorflow/probability/tree/main/tensorflow_probability/examples 
- name: Poster
  url: https://jmzeng.github.io/uploads/BDL-Poster-A-1_v2.pdf
---
