@misc{zeng_relevance_2018,
 abstract = {One of the main challenges of deep learning tools is their inability to capture model uncertainty. While Bayesian deep learning can be used to tackle the problem, Bayesian neural networks often require more time and computational power to train than deterministic networks. Our work explores whether fully Bayesian networks are needed to successfully capture model uncertainty. We vary the number and position of Bayesian layers in a network and compare their performance on active learning with the MNIST dataset. We found that we can fully capture the model uncertainty by using only a few Bayesian layers near the output of the network, combining the advantages of deterministic and Bayesian networks.},
 author = {Zeng, Jiaming and Lesnikowski, Adam and Alvarez, Jose M.},
 copyright = {All rights reserved},
 file = {arXiv Fulltext PDF:/Users/jiaming/Zotero/storage/WIQ6MZUV/Zeng et al. - 2018 - The Relevance of Bayesian Layer Positioning to Mod.pdf:application/pdf;arXiv.org Snapshot:/Users/jiaming/Zotero/storage/68EDRKVR/1811.html:text/html},
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
 month = {November},
 note = {arXiv:1811.12535 [cs, stat]},
 publisher = {arXiv},
 title = {The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep Bayesian Active Learning},
 url = {http://arxiv.org/abs/1811.12535},
 urldate = {2023-12-16},
 year = {2018}
}
